#!/usr/bin/env python3
import sys
import numpy as np
import pandas as pd

INPUT_CSV = "data/absa_features.csv"
OUT_CSV   = "data/absa_features_target.csv"

def main():
    # --- lightweight part runs even if transformers/torch are not installed ---
    df = pd.read_csv(INPUT_CSV)

    # Add TARGET from 5-day return
    df["TARGET"] = np.where(df["Perc_Return_D5"] > 0, "pos", "neg")

    # Save and quick date split
    df.to_csv(OUT_CSV, index=False)
    print(f"File successfully saved to {OUT_CSV}")

    train_df = df[df["Date"] < "2023-10-01"]
    test_df  = df[df["Date"] >= "2023-10-01"]
    print(f"Train size: {len(train_df)}, Test size: {len(test_df)}")

    # --- only import heavy libs when you actually start modeling ---
    # from transformers import BertTokenizer, BertForSequenceClassification
    # import evaluate
    # from datasets import load_dataset
    # (add your BERT baseline here)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print("Error:", e)
        sys.exit(1)
